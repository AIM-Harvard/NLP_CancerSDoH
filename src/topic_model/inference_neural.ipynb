{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmnt.estimator import BowEstimator\n",
    "import numpy as np\n",
    "import gluonnlp as nlp\n",
    "import os\n",
    "import umap\n",
    "from tmnt.preprocess.vectorizer import TMNTVectorizer\n",
    "from tmnt.configuration import TMNTConfigBOW\n",
    "from tmnt.trainer import BowVAETrainer\n",
    "from tmnt.selector import BaseSelector\n",
    "import pyLDAvis\n",
    "import funcy\n",
    "from tmnt.inference import BowVAEInferencer\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from utils import filter_data, grab_sections, load_data\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_path = 'PATH'\n",
    "thor_path = 'PATH'\n",
    "\n",
    "broadband_data = load_data(bb_path)\n",
    "thoracic_data = load_data(thor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([broadband_data, thoracic_data])\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use notes with the following sections: Interval History, Assesment and Plan, & History of Present Illness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['text'].apply(grab_sections) != '']\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create demographic dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_df = filter_data(data, 'insurance', ['low'], include=True)\n",
    "reg_df = filter_data(data, 'insurance', ['reg'], include=True)\n",
    "female_df = filter_data(data, 'Gender', ['Female'], include=True)\n",
    "male_df = filter_data(data, 'Gender', ['Male'], include=True)\n",
    "nwh_df = filter_data(data, 'Race_group', ['White_NonHispanic', 'Unknown'])\n",
    "wh_df = filter_data(data, 'Race_group', ['White_NonHispanic'], include=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 100 patients per demographic for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test_pmrns = random.sample(list(set(female_df['PMRN'])), 100)\n",
    "m_test_pmrns = random.sample(list(set(male_df['PMRN'])), 100)\n",
    "nw_test_pmrns = random.sample(list(set(nwh_df['PMRN'])), 100)\n",
    "w_test_pmrns = random.sample(list(set(wh_df['PMRN'])), 100)\n",
    "l_test_pmrns = random.sample(list(set(low_df['PMRN'])), 100)\n",
    "r_test_pmrns = random.sample(list(set(reg_df['PMRN'])), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_test_df = female_df[female_df['PMRN'].isin(set(f_test_pmrns))]\n",
    "reg_test_df = reg_df[reg_df['PMRN'].isin(r_test_pmrns)]\n",
    "male_test_df = male_df[male_df['PMRN'].isin(m_test_pmrns)]\n",
    "nwh_test_df = nwh_df[nwh_df['PMRN'].isin(nw_test_pmrns)]\n",
    "wh_test_df = wh_df[wh_df['PMRN'].isin(w_test_pmrns)]\n",
    "low_test_df = low_df[low_df['PMRN'].isin(l_test_pmrns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate patients from training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_pmrns = m_test_pmrns+f_test_pmrns+nw_test_pmrns+w_test_pmrns+l_test_pmrns+r_test_pmrns\n",
    "train_df = data[~(data['PMRN'].isin(all_test_pmrns))]\n",
    "assert(len(set(train_df['PMRN']).intersection(set(all_test_pmrns))) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_notes = train_df['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sectionize training data to include 300 tokens of each section: Interval History, Assesment and Plan, & History of Present Illness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = [grab_sections(fnote, token_len=300) for fnote in train_notes if grab_sections(fnote)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_space = './config_files/config_nolabels.yaml'\n",
    "tmnt_config = TMNTConfigBOW(config_space).get_configspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs_path = './inference_all_providers_model_outs/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TMNTVectorizer(vocab_size=4000)\n",
    "X, _ = tf_vectorizer.fit_transform(notes)\n",
    "vocab = tf_vectorizer.get_vocab()\n",
    "\n",
    "selector = BaseSelector(tmnt_config, iterations=50, searcher='random',\n",
    "                        scheduler='hyperband', cpus_per_task=2, log_dir='./inference_all_providers_models/_full_model_out')\n",
    "\n",
    "trainer = BowVAETrainer(vocab, X, X, log_out_dir='./inference_all_providers_models/_full_exps', model_out_dir='./inference_all_providers_models/_full_model_out') # Same train/validation set\n",
    "estimator = selector.select_model(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer = BowVAEInferencer(estimator[0], pre_vectorizer= tf_vectorizer)\n",
    "full_model_dict = inferencer.get_pyldavis_details(X)\n",
    "pylda_opts = funcy.merge(full_model_dict, {'mds': 'mmds'})\n",
    "vis_data = pyLDAvis.prepare(**pylda_opts)\n",
    "pyLDAvis.save_html(vis_data, model_outputs_path+'radOnc_EMR_topics.html')\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer.save(model_dir='./inference_all_providers_models/_full_model_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out model perplexity and coherence (NPMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_inference = BowVAEInferencer.from_saved(model_dir='./inference_all_providers_models/_full_model_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_inference.get_top_k_words_per_topic(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_test_notes = female_test_df['text'].to_list()\n",
    "reg_test_notes = reg_test_df['text'].to_list()\n",
    "male_test_notes = male_test_df['text'].to_list()\n",
    "nwh_test_notes = nwh_test_df['text'].to_list()\n",
    "wh_test_notes = wh_test_df['text'].to_list()\n",
    "low_test_notes = low_test_df['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sectionize inference data based on same rules as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_test_notes = [grab_sections(note) for note in wh_test_notes]\n",
    "nwh_test_notes = [grab_sections(note) for note in nwh_test_notes]\n",
    "male_test_notes = [grab_sections(note) for note in male_test_notes]\n",
    "female_test_notes = [grab_sections(note) for note in female_test_notes]\n",
    "low_test_notes = [grab_sections(note) for note in low_test_notes]\n",
    "reg_test_notes = [grab_sections(note) for note in reg_test_notes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append insurance information to each datapoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pmrns = set(low_df['PMRN'])\n",
    "reg_pmrns = set(reg_df['PMRN'])\n",
    "\n",
    "wh_test_info = []\n",
    "for note, pmrn, race, gender in zip(wh_test_notes, wh_test_df['PMRN'], wh_test_df['Race_group'], wh_test_df['Gender']):\n",
    "    if pmrn in low_pmrns:\n",
    "        inc = 'low'\n",
    "    elif pmrn in reg_pmrns:\n",
    "        inc = 'non-low'\n",
    "    else:\n",
    "        inc = 'unknown'\n",
    "    wh_test_info.append((note, pmrn, race, gender, inc))\n",
    "\n",
    "nwh_test_info = []\n",
    "for note, pmrn, race, gender in zip(nwh_test_notes, nwh_test_df['PMRN'], nwh_test_df['Race_group'], nwh_test_df['Gender']):\n",
    "    if pmrn in low_pmrns:\n",
    "        inc = 'low'\n",
    "    elif pmrn in reg_pmrns:\n",
    "        inc = 'non-low'\n",
    "    else:\n",
    "        inc = 'unknown'\n",
    "    nwh_test_info.append((note, pmrn, race, gender, inc))\n",
    "\n",
    "male_test_info = []\n",
    "for note, pmrn, race, gender in zip(male_test_notes, male_test_df['PMRN'], male_test_df['Race_group'], male_test_df['Gender']):\n",
    "    if pmrn in low_pmrns:\n",
    "        inc = 'low'\n",
    "    elif pmrn in reg_pmrns:\n",
    "        inc = 'non-low'\n",
    "    else:\n",
    "        inc = 'unknown'\n",
    "    male_test_info.append((note, pmrn, race, gender, inc))\n",
    "\n",
    "female_test_info = []\n",
    "for note, pmrn, race, gender in zip(female_test_notes, female_test_df['PMRN'], female_test_df['Race_group'], female_test_df['Gender']):\n",
    "    if pmrn in low_pmrns:\n",
    "        inc = 'low'\n",
    "    elif pmrn in reg_pmrns:\n",
    "        inc = 'non-low'\n",
    "    else:\n",
    "        inc = 'unknown'\n",
    "    female_test_info.append((note, pmrn, race, gender, inc))\n",
    "\n",
    "low_test_info = []\n",
    "for note, pmrn, race, gender in zip(low_test_notes, low_test_df['PMRN'], low_test_df['Race_group'], low_test_df['Gender']):\n",
    "    if pmrn in low_pmrns:\n",
    "        inc = 'low'\n",
    "    elif pmrn in reg_pmrns:\n",
    "        inc = 'non-low'\n",
    "    else:\n",
    "        inc = 'unknown'\n",
    "    low_test_info.append((note, pmrn, race, gender, inc))\n",
    "\n",
    "reg_test_info = []\n",
    "for note, pmrn, race, gender in zip(reg_test_notes, reg_test_df['PMRN'], reg_test_df['Race_group'], reg_test_df['Gender']):\n",
    "    if pmrn in low_pmrns:\n",
    "        inc = 'low'\n",
    "    elif pmrn in reg_pmrns:\n",
    "        inc = 'non-low'\n",
    "    else:\n",
    "        inc = 'unknown'\n",
    "    reg_test_info.append((note, pmrn, race, gender, inc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(reg_test_info)==len(reg_test_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 4000 notes for each demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_test_info = random.sample(wh_test_info, 4000)\n",
    "nwh_test_info = random.sample(nwh_test_info, 4000)\n",
    "male_test_info = random.sample(male_test_info, 4000)\n",
    "female_test_info = random.sample(female_test_info, 4000)\n",
    "low_test_info = random.sample(low_test_info, 4000)\n",
    "reg_test_info = random.sample(reg_test_info, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_test_notes = [note[0] for note in wh_test_info]\n",
    "nwh_test_notes = [note[0]  for note in nwh_test_info]\n",
    "male_test_notes = [note[0]  for note in male_test_info]\n",
    "female_test_notes = [note[0]  for note in female_test_info]\n",
    "low_test_notes = [note[0]  for note in low_test_info]\n",
    "reg_test_notes = [note[0]  for note in reg_test_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get topic encodings for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_encodings = reloaded_inference.encode_texts(wh_test_notes)\n",
    "nwh_encodings = reloaded_inference.encode_texts(nwh_test_notes)\n",
    "male_encodings = reloaded_inference.encode_texts(male_test_notes)\n",
    "female_encodings = reloaded_inference.encode_texts(female_test_notes)\n",
    "low_encodings = reloaded_inference.encode_texts(low_test_notes)\n",
    "reg_encodings = reloaded_inference.encode_texts(reg_test_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export enxodings to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_encodings = [enc.tolist() for enc in wh_encodings]\n",
    "nwh_encodings = [enc.tolist() for enc in nwh_encodings]\n",
    "female_encodings = [enc.tolist() for enc in female_encodings]\n",
    "male_encodings = [enc.tolist() for enc in male_encodings]\n",
    "low_encodings = [enc.tolist() for enc in low_encodings]\n",
    "reg_encodings = [enc.tolist() for enc in reg_encodings]\n",
    "out_d = {'white':wh_encodings, 'non_white':nwh_encodings, 'female':female_encodings, 'male':male_encodings, 'low_inc':low_encodings, 'reg_inc':reg_encodings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('all_provider_inference_encodings.json' ,'w') as j_out:\n",
    "    json.dump(out_d, j_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('bwh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "001a8694a61500c4b34637b06f1b04f831c2773fc087ae5506206b8465705b8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
